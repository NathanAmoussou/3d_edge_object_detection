{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# Export du mod√®le YOLO11n de base (non fine-tun√©)\n- Mod√®le pr√©-entra√Æn√© sur COCO (80 classes)\n- Test sur COCO128 (sous-ensemble de 128 images), puis export en ONNX et blob"
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:28:38.188078990Z",
     "start_time": "2025-12-26T20:28:38.121288310Z"
    }
   },
   "source": "import os\nfrom pathlib import Path\n\nimport blobconverter\nfrom ultralytics import YOLO\n\nROOT_DIR = Path(__file__).parent.parent.resolve() if \"__file__\" in dir() else Path.cwd().parent.resolve()",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "config",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:28:39.769652747Z",
     "start_time": "2025-12-26T20:28:39.703414971Z"
    }
   },
   "source": "BASE_WEIGHTS = str(ROOT_DIR / \"models/base/yolo11n.pt\")\nOUTPUT_DIR = str(ROOT_DIR / \"models/base\")\n\nIMGSZ = 640\nCONF = 0.25",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "load_model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:28:45.332101326Z",
     "start_time": "2025-12-26T20:28:45.207465819Z"
    }
   },
   "source": [
    "model = YOLO(BASE_WEIGHTS)\n",
    "print(f\"Modele charge: {BASE_WEIGHTS}\")\n",
    "print(f\"Nombre de classes: {len(model.names)}\")\n",
    "print(f\"Classes: {list(model.names.values())[:10]}...\")  # Affiche les 10 premieres"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modele charge: /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.pt\n",
      "Nombre de classes: 80\n",
      "Classes: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light']...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "test_inference",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:28:54.915165504Z",
     "start_time": "2025-12-26T20:28:48.531852909Z"
    }
   },
   "source": "# Validation sur COCO128 (telecharge automatiquement ~7MB)\nmetrics = model.val(data=\"coco128.yaml\", imgsz=IMGSZ, device=0)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Resultats sur COCO128\")\nprint(\"=\"*50)\nprint(f\"mAP50-95: {float(metrics.box.map):.4f}\")\nprint(f\"mAP50   : {float(metrics.box.map50):.4f}\")\nprint(f\"mAP75   : {float(metrics.box.map75):.4f}\")\nprint(f\"Precision: {float(metrics.box.mp):.4f}\")\nprint(f\"Recall   : {float(metrics.box.mr):.4f}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.241 üöÄ Python-3.11.14 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 7806MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "WARNING ‚ö†Ô∏è Dataset 'coco128.yaml' images not found, missing path '/home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets/coco128/images/train2017'\n",
      "\u001B[KDownloading https://ultralytics.com/assets/coco128.zip to '/home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets/coco128.zip': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.7MB 20.9MB/s 0.3s.3s<0.0s8s\n",
      "\u001B[KUnzipping /home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets/coco128.zip to /home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets/coco128...: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 263/263 3.8Kfiles/s 0.1s\n",
      "Dataset download success ‚úÖ (1.3s), saved to \u001B[1m/home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets\u001B[0m\n",
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1244.7¬±440.5 MB/s, size: 47.0 KB)\n",
      "\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning /home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 128/128 2.1Kit/s 0.1s\n",
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /home/nathan/Documents/education/master_2/cours/deep_learning_for_image/TP6/datasets/coco128/labels/train2017.cache\n",
      "\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.9it/s 1.6s0.4s\n",
      "                   all        128        929      0.663      0.589      0.671      0.505\n",
      "                person         61        254      0.798      0.686       0.79      0.543\n",
      "               bicycle          3          6      0.388      0.167      0.424      0.269\n",
      "                   car         12         46      0.656      0.196      0.243      0.152\n",
      "            motorcycle          4          5      0.654          1      0.995      0.789\n",
      "              airplane          5          6      0.844      0.833      0.955      0.845\n",
      "                   bus          5          7      0.775      0.714      0.726      0.654\n",
      "                 train          3          3      0.749      0.996       0.83      0.748\n",
      "                 truck          5         12      0.471       0.25      0.379      0.236\n",
      "                  boat          2          6      0.333      0.333      0.456      0.342\n",
      "         traffic light          4         14      0.504      0.143      0.234      0.152\n",
      "             stop sign          2          2      0.812          1      0.995      0.798\n",
      "                 bench          5          9          1      0.415      0.657      0.357\n",
      "                  bird          2         16      0.951          1      0.995       0.66\n",
      "                   cat          4          4      0.764          1      0.995      0.834\n",
      "                   dog          9          9      0.636      0.778      0.905      0.712\n",
      "                 horse          1          2       0.56          1      0.995      0.796\n",
      "              elephant          4         17      0.873      0.941      0.947      0.751\n",
      "                  bear          1          1      0.613          1      0.995      0.995\n",
      "                 zebra          2          4      0.848          1      0.995      0.971\n",
      "               giraffe          4          9      0.817      0.889      0.947      0.703\n",
      "              backpack          4          6      0.818      0.333      0.412      0.219\n",
      "              umbrella          4         18      0.906      0.535      0.738      0.409\n",
      "               handbag          9         19      0.358     0.0526       0.17      0.115\n",
      "                   tie          6          7      0.972      0.571       0.77       0.55\n",
      "              suitcase          2          4      0.682          1      0.995      0.618\n",
      "               frisbee          5          5      0.687        0.8      0.759      0.673\n",
      "                  skis          1          1      0.524          1      0.995      0.431\n",
      "             snowboard          2          7      0.652      0.539      0.735      0.447\n",
      "           sports ball          6          6      0.555      0.424      0.521      0.328\n",
      "                  kite          2         10      0.683      0.434      0.523       0.19\n",
      "          baseball bat          4          4      0.483      0.242      0.175      0.095\n",
      "        baseball glove          4          7      0.701      0.429      0.429      0.226\n",
      "            skateboard          3          5      0.971        0.6      0.724      0.469\n",
      "         tennis racket          5          7      0.535      0.499      0.564      0.324\n",
      "                bottle          6         18      0.625      0.333      0.497      0.314\n",
      "            wine glass          5         16      0.671      0.438      0.654      0.358\n",
      "                   cup         10         36      0.725      0.278      0.405      0.287\n",
      "                  fork          6          6      0.579      0.167      0.244      0.206\n",
      "                 knife          7         16      0.791        0.5      0.622      0.411\n",
      "                 spoon          5         22      0.896      0.273      0.431      0.298\n",
      "                  bowl          9         28      0.571      0.714      0.675      0.569\n",
      "                banana          1          1      0.427          1      0.995      0.895\n",
      "              sandwich          2          2      0.361        0.5      0.448      0.447\n",
      "                orange          1          4          1          0      0.828      0.544\n",
      "              broccoli          4         11      0.356      0.182      0.238      0.213\n",
      "                carrot          3         24      0.723        0.5      0.645      0.434\n",
      "               hot dog          1          2      0.523          1      0.995      0.995\n",
      "                 pizza          5          5      0.615          1      0.995      0.844\n",
      "                 donut          2         14        0.6          1      0.868      0.774\n",
      "                  cake          4          4      0.581          1      0.995      0.785\n",
      "                 chair          9         35      0.475      0.543       0.54      0.307\n",
      "                 couch          5          6      0.611      0.667      0.746      0.585\n",
      "          potted plant          9         14      0.802        0.5      0.715      0.524\n",
      "                   bed          3          3      0.698       0.79      0.913       0.69\n",
      "          dining table         10         13      0.531      0.615      0.561      0.464\n",
      "                toilet          2          2      0.613        0.5      0.551      0.536\n",
      "                    tv          2          2      0.633          1      0.995      0.821\n",
      "                laptop          2          3          1      0.404      0.775      0.654\n",
      "                 mouse          2          2          1          0      0.135     0.0135\n",
      "                remote          5          8      0.696        0.5      0.524      0.445\n",
      "            cell phone          5          8          1          0        0.2     0.0956\n",
      "             microwave          3          3      0.484          1      0.995      0.897\n",
      "                  oven          5          5      0.231        0.4      0.356      0.292\n",
      "                  sink          4          6      0.303      0.167      0.268      0.198\n",
      "          refrigerator          5          5      0.829          1      0.995      0.667\n",
      "                  book          6         29      0.621      0.103      0.392      0.223\n",
      "                 clock          8          9      0.809      0.778      0.866      0.731\n",
      "                  vase          2          2      0.452          1      0.995      0.895\n",
      "              scissors          1          1          0          0          0          0\n",
      "            teddy bear          6         21      0.674      0.333      0.651      0.431\n",
      "            toothbrush          2          5          1      0.863      0.995       0.62\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001B[1m/home/nathan/Documents/GitHub/3d_edge_object_detection/notebooks/runs/detect/val3\u001B[0m\n",
      "\n",
      "==================================================\n",
      "Resultats sur COCO128\n",
      "==================================================\n",
      "mAP50-95: 0.5051\n",
      "mAP50   : 0.6714\n",
      "mAP75   : 0.5420\n",
      "Precision: 0.6631\n",
      "Recall   : 0.5894\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "export_onnx",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:17:40.046321821Z",
     "start_time": "2025-12-26T20:17:39.279834399Z"
    }
   },
   "source": [
    "onnx_path = model.export(\n",
    "    format=\"onnx\",\n",
    "    imgsz=IMGSZ,\n",
    "    opset=13,\n",
    "    simplify=True,\n",
    "    dynamic=False,\n",
    ")\n",
    "\n",
    "print(\"ONNX exporte:\", onnx_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.241 üöÄ Python-3.11.14 torch-2.9.1+cu128 CPU (Intel Core i9-14900HX)\n",
      "\n",
      "\u001B[34m\u001B[1mPyTorch:\u001B[0m starting from '/home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m starting export with onnx 1.20.0 opset 13...\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m slimming with onnxslim 0.1.80...\n",
      "\u001B[34m\u001B[1mONNX:\u001B[0m export success ‚úÖ 0.6s, saved as '/home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.onnx' (10.2 MB)\n",
      "\n",
      "Export complete (0.7s)\n",
      "Results saved to \u001B[1m/home/nathan/Documents/GitHub/3d_edge_object_detection/models/base\u001B[0m\n",
      "Predict:         yolo predict task=detect model=/home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ONNX exporte: /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.onnx\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "export_blob",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:17:57.056469511Z",
     "start_time": "2025-12-26T20:17:42.439934358Z"
    }
   },
   "source": [
    "blob_path = blobconverter.from_onnx(\n",
    "    model=onnx_path,\n",
    "    data_type=\"FP16\",\n",
    "    shaves=6,\n",
    "    output_dir=OUTPUT_DIR,\n",
    ")\n",
    "\n",
    "print(\"BLOB exporte:\", blob_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n_openvino_2022.1_6shave.blob...\n",
      "[==================================================]\n",
      "Done\n",
      "BLOB exporte: /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n_openvino_2022.1_6shave.blob\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "summary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T20:18:16.283991449Z",
     "start_time": "2025-12-26T20:18:16.229493222Z"
    }
   },
   "source": "print(\"\\n\" + \"=\"*50)\nprint(\"RESUME - Modele YOLO11n BASE (non fine-tune)\")\nprint(\"=\"*50)\nprint(f\"Classes: 80 (COCO)\")\nprint(f\"Input size: {IMGSZ}x{IMGSZ}\")\nprint(f\"Fichiers dans: {OUTPUT_DIR}\")\nprint(f\"  - PT:   {BASE_WEIGHTS}\")\nprint(f\"  - ONNX: {onnx_path}\")\nprint(f\"  - BLOB: {blob_path}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RESUME - Modele YOLO11n BASE (non fine-tune)\n",
      "==================================================\n",
      "Classes: 80 (COCO)\n",
      "Input size: 640x640\n",
      "Fichiers dans: /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base\n",
      "  - PT:   /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.pt\n",
      "  - ONNX: /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n.onnx\n",
      "  - BLOB: /home/nathan/Documents/GitHub/3d_edge_object_detection/models/base/yolo11n_openvino_2022.1_6shave.blob\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
